{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "name": "ruGPT3XL_generation",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/php4nuke/ru-gpts/blob/master/examples/ruGPT3XL_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4tnxQoRogVV"
      },
      "source": [
        "# Install env"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW1w_w0itrLP"
      },
      "source": [
        "!export CUDA_HOME=/usr/local/cuda-10.1\n",
        "!git clone https://github.com/NVIDIA/apex\n",
        "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex\n",
        "!apt-get install llvm-9-dev\n",
        "!pip install cpufeature\n",
        "!pip install triton==0.2.3\n",
        "!DS_BUILD_CPU_ADAM=1 DS_BUILD_SPARSE_ATTN=1 pip install deepspeed==0.3.7\n",
        "!ds_report\n",
        "# And this cell should be run without errors\n",
        "import deepspeed.ops.sparse_attention.sparse_attn_op\n",
        "!git clone https://github.com/php4nuke/ru-gpts.git\n",
        "!pip install transformers==3.5.1\n",
        "!pip install natsort"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU8lvJHAjpPQ"
      },
      "source": [
        "### Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnTy1SEajpPV"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import sys\n",
        "sys.path.append(\"ru-gpts/gw\")\n",
        "from generation_wrapper import RuGPT3XL\n",
        "gpt = RuGPT3XL.from_pretrained(\"sberbank-ai/rugpt3xl\", seq_len=1024)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lgi-JUNijpPY"
      },
      "source": [
        "### Simple generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wla741VxjpPY"
      },
      "source": [
        "def filter_resuls(nr):\n",
        "    return [x[:x.find(\"<|endoftext|>\")] for x in nr]\n",
        "\n",
        "import requests\n",
        "t_in = requests.post('https://gpt3.000webhostapp.com/gpt.php', data = {'txt':''})\n",
        "\n",
        "while t_in.text != \"\":\n",
        "    t_out = filter_resuls(gpt.generate(\n",
        "        t_in.text,\n",
        "        min_length=300,\n",
        "        max_length=500,\n",
        "        temperature=0.8,\n",
        "        no_repeat_ngram_size=3,\n",
        "        repetition_penalty=2.0,\n",
        "    ))\n",
        "    t_in = requests.post('https://gpt3.000webhostapp.com/gpt.php', data = {'txt':t_out})"
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}